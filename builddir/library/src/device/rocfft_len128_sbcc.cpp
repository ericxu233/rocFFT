/*
 * Stockham kernels generated by:
 * 
 *     /home/ugrad/ugrad003/roctosycl/rocFFT/library/src/device/kernel-generator.py --pattern=all --precision=all --groups=150 --manual-small= --manual-large= generate /home/ugrad/ugrad003/roctosycl/rocFFT/builddir/library/src/device/generator/rocfft-kernel-generator
 * 
 * Generator is: /home/ugrad/ugrad003/roctosycl/rocFFT/library/src/device/kernel-generator.py
 * Kernel is: namespace(factors=[8, 4, 4], length=128, scheme='CS_KERNEL_STOCKHAM_BLOCK_CC', threads_per_block=512, use_3steps_large_twd={'sp': 'true', 'dp': 'false'})
 */

#include "kernel_launch.h"
#include "real2complex.h"
#include "rocfft_butterfly_template.h"
#include <hip/hip_runtime.h>

/* stockham.py:765 */
template <typename scalar_type,
          StrideBin sb,
          bool      apply_large_twiddle,
          size_t    large_twiddle_base = 8>
__device__ void ip_forward_length128_SBCC_device(scalar_type* __restrict__ lds,
                                                 const scalar_type* __restrict__ twiddles,
                                                 size_t             stride_lds,
                                                 unsigned int       offset_lds,
                                                 bool               write,
                                                 const scalar_type* large_twiddles,
                                                 size_t             trans_local)
{
    size_t       thread;
    scalar_type  R[8];
    scalar_type  W;
    scalar_type  t;
    const size_t lstride = (sb == SB_UNIT) ? (1) : (stride_lds);
    thread               = threadIdx.x % 32; /* stockham.py:731 */

    // pass 0
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 16) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 48) * lstride]; /* stockham.py:542 */
    R[4] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[5] = lds[offset_lds + (thread + 80) * lstride]; /* stockham.py:542 */
    R[6] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */
    R[7] = lds[offset_lds + (thread + 112) * lstride]; /* stockham.py:542 */

    FwdRad8B1(&R[0], &R[1], &R[2], &R[3], &R[4], &R[5], &R[6], &R[7]); /* stockham.py:566 */

    __syncthreads();
    if(write && thread < 16)
    {
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 1) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 2) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 3) * lstride]
            = R[3]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 4) * lstride]
            = R[4]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 5) * lstride]
            = R[5]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 6) * lstride]
            = R[6]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 7) * lstride]
            = R[7]; /* stockham.py:577 */
    }

    // pass 1
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = twiddles[7 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = twiddles[8 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = twiddles[9 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    FwdRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 8) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 16) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 24) * lstride]
            = R[3]; /* stockham.py:577 */
    }

    // pass 2
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = twiddles[31 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = twiddles[32 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = twiddles[33 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    FwdRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    if(apply_large_twiddle)
    {
        // large twiddle multiplication
        W = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 0) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[0].x - W.y * R[0].y; /* stockham.py:283 */
        t.y  = W.y * R[0].x + W.x * R[0].y; /* stockham.py:284 */
        R[0] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 32) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:283 */
        t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:284 */
        R[1] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 64) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:283 */
        t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:284 */
        R[2] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 96) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:283 */
        t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:284 */
        R[3] = t; /* stockham.py:285 */
    }
    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 32) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 64) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 96) * lstride]
            = R[3]; /* stockham.py:577 */
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__
    __launch_bounds__(512) void ip_forward_length128_SBCC(const scalar_type* __restrict__ twiddles,
                                                          const scalar_type* large_twiddles,
                                                          const size_t       dim,
                                                          const size_t* __restrict__ lengths,
                                                          const size_t* __restrict__ stride,
                                                          const size_t       nbatch,
                                                          const unsigned int lds_padding,
                                                          void* __restrict__ load_cb_fn,
                                                          void* __restrict__ load_cb_data,
                                                          uint32_t load_cb_lds_bytes,
                                                          void* __restrict__ store_cb_fn,
                                                          void* __restrict__ store_cb_data,
                                                          scalar_type* __restrict__ buf)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset           = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0  = (sb == SB_UNIT) ? (1) : (stride[0]);
    auto         load_cb  = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset      = tile_index * 16 * stride[1]; /* stockham.py:457 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset        = offset + index_along_d * stride[d]; /* stockham.py:463 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset     = offset + batch * stride[dim]; /* stockham.py:467 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf, offset + tid1 * stride[1] + (tid0 + 0) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 32) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 64) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 96) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 0) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 32) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 64) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 96) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    ip_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 0) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 32) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 64) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 96) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 0) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 32) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 64) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 96) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void ip_forward_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ bufre,
    real_type_t<scalar_type>* __restrict__ bufim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset           = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0  = (sb == SB_UNIT) ? (1) : (stride[0]);
    auto         load_cb  = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset      = tile_index * 16 * stride[1]; /* stockham.py:457 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset        = offset + index_along_d * stride[d]; /* stockham.py:463 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset     = offset + batch * stride[dim]; /* stockham.py:467 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    ip_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
/* stockham.py:765 */
template <typename scalar_type,
          StrideBin sb,
          bool      apply_large_twiddle,
          size_t    large_twiddle_base = 8>
__device__ void op_forward_length128_SBCC_device(scalar_type* __restrict__ lds,
                                                 const scalar_type* __restrict__ twiddles,
                                                 size_t             stride_lds,
                                                 unsigned int       offset_lds,
                                                 bool               write,
                                                 const scalar_type* large_twiddles,
                                                 size_t             trans_local)
{
    size_t       thread;
    scalar_type  R[8];
    scalar_type  W;
    scalar_type  t;
    const size_t lstride = (sb == SB_UNIT) ? (1) : (stride_lds);
    thread               = threadIdx.x % 32; /* stockham.py:731 */

    // pass 0
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 16) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 48) * lstride]; /* stockham.py:542 */
    R[4] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[5] = lds[offset_lds + (thread + 80) * lstride]; /* stockham.py:542 */
    R[6] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */
    R[7] = lds[offset_lds + (thread + 112) * lstride]; /* stockham.py:542 */

    FwdRad8B1(&R[0], &R[1], &R[2], &R[3], &R[4], &R[5], &R[6], &R[7]); /* stockham.py:566 */

    __syncthreads();
    if(write && thread < 16)
    {
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 1) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 2) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 3) * lstride]
            = R[3]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 4) * lstride]
            = R[4]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 5) * lstride]
            = R[5]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 6) * lstride]
            = R[6]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 7) * lstride]
            = R[7]; /* stockham.py:577 */
    }

    // pass 1
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = twiddles[7 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = twiddles[8 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = twiddles[9 + 3 * (thread % 8)]; /* stockham.py:554 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    FwdRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 8) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 16) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 24) * lstride]
            = R[3]; /* stockham.py:577 */
    }

    // pass 2
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = twiddles[31 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = twiddles[32 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = twiddles[33 + 3 * (thread % 32)]; /* stockham.py:554 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    FwdRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    if(apply_large_twiddle)
    {
        // large twiddle multiplication
        W = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 0) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[0].x - W.y * R[0].y; /* stockham.py:283 */
        t.y  = W.y * R[0].x + W.x * R[0].y; /* stockham.py:284 */
        R[0] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 32) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:283 */
        t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:284 */
        R[1] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 64) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:283 */
        t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:284 */
        R[2] = t; /* stockham.py:285 */
        W    = TW2step<scalar_type, large_twiddle_base>(
            large_twiddles, ((thread % 32) + 96) * trans_local); /* stockham.py:282 */
        t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:283 */
        t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:284 */
        R[3] = t; /* stockham.py:285 */
    }
    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 32) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 64) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 96) * lstride]
            = R[3]; /* stockham.py:577 */
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__
    __launch_bounds__(512) void op_forward_length128_SBCC(const scalar_type* __restrict__ twiddles,
                                                          const scalar_type* large_twiddles,
                                                          const size_t       dim,
                                                          const size_t* __restrict__ lengths,
                                                          const size_t* __restrict__ stride_in,
                                                          const size_t* __restrict__ stride_out,
                                                          const size_t       nbatch,
                                                          const unsigned int lds_padding,
                                                          void* __restrict__ load_cb_fn,
                                                          void* __restrict__ load_cb_data,
                                                          uint32_t load_cb_lds_bytes,
                                                          void* __restrict__ store_cb_fn,
                                                          void* __restrict__ store_cb_data,
                                                          scalar_type* __restrict__ buf_in,
                                                          scalar_type* __restrict__ buf_out)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_forward_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    scalar_type* __restrict__ buf_in,
    real_type_t<scalar_type>* __restrict__ buf_outre,
    real_type_t<scalar_type>* __restrict__ buf_outim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_forward_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ buf_inre,
    real_type_t<scalar_type>* __restrict__ buf_inim,
    scalar_type* __restrict__ buf_out)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_forward_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ buf_inre,
    real_type_t<scalar_type>* __restrict__ buf_inim,
    real_type_t<scalar_type>* __restrict__ buf_outre,
    real_type_t<scalar_type>* __restrict__ buf_outim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_forward_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
/* stockham.py:765 */
template <typename scalar_type,
          StrideBin sb,
          bool      apply_large_twiddle,
          size_t    large_twiddle_base = 8>
__device__ void ip_inverse_length128_SBCC_device(scalar_type* __restrict__ lds,
                                                 const scalar_type* __restrict__ twiddles,
                                                 size_t             stride_lds,
                                                 unsigned int       offset_lds,
                                                 bool               write,
                                                 const scalar_type* large_twiddles,
                                                 size_t             trans_local)
{
    size_t       thread;
    scalar_type  R[8];
    scalar_type  W;
    scalar_type  t;
    const size_t lstride = (sb == SB_UNIT) ? (1) : (stride_lds);
    thread               = threadIdx.x % 32; /* stockham.py:731 */

    // pass 0
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 16) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 48) * lstride]; /* stockham.py:542 */
    R[4] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[5] = lds[offset_lds + (thread + 80) * lstride]; /* stockham.py:542 */
    R[6] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */
    R[7] = lds[offset_lds + (thread + 112) * lstride]; /* stockham.py:542 */

    InvRad8B1(&R[0], &R[1], &R[2], &R[3], &R[4], &R[5], &R[6], &R[7]); /* stockham.py:566 */

    __syncthreads();
    if(write && thread < 16)
    {
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 1) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 2) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 3) * lstride]
            = R[3]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 4) * lstride]
            = R[4]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 5) * lstride]
            = R[5]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 6) * lstride]
            = R[6]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 7) * lstride]
            = R[7]; /* stockham.py:577 */
    }

    // pass 1
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = {twiddles[7 + 3 * (thread % 8)].x,
         -twiddles[7 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = {twiddles[8 + 3 * (thread % 8)].x,
         -twiddles[8 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = {twiddles[9 + 3 * (thread % 8)].x,
         -twiddles[9 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    InvRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 8) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 16) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 24) * lstride]
            = R[3]; /* stockham.py:577 */
    }

    // pass 2
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = {twiddles[31 + 3 * (thread % 32)].x,
         -twiddles[31 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = {twiddles[32 + 3 * (thread % 32)].x,
         -twiddles[32 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = {twiddles[33 + 3 * (thread % 32)].x,
         -twiddles[33 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    InvRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    if(apply_large_twiddle)
    {
        // large twiddle multiplication
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 0) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 0) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[0].x - W.y * R[0].y; /* stockham.py:283 */
        t.y  = W.y * R[0].x + W.x * R[0].y; /* stockham.py:284 */
        R[0] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 32) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 32) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:283 */
        t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:284 */
        R[1] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 64) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 64) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:283 */
        t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:284 */
        R[2] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 96) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 96) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:283 */
        t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:284 */
        R[3] = t; /* stockham.py:285 */
    }
    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 32) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 64) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 96) * lstride]
            = R[3]; /* stockham.py:577 */
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__
    __launch_bounds__(512) void ip_inverse_length128_SBCC(const scalar_type* __restrict__ twiddles,
                                                          const scalar_type* large_twiddles,
                                                          const size_t       dim,
                                                          const size_t* __restrict__ lengths,
                                                          const size_t* __restrict__ stride,
                                                          const size_t       nbatch,
                                                          const unsigned int lds_padding,
                                                          void* __restrict__ load_cb_fn,
                                                          void* __restrict__ load_cb_data,
                                                          uint32_t load_cb_lds_bytes,
                                                          void* __restrict__ store_cb_fn,
                                                          void* __restrict__ store_cb_data,
                                                          scalar_type* __restrict__ buf)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset           = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0  = (sb == SB_UNIT) ? (1) : (stride[0]);
    auto         load_cb  = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset      = tile_index * 16 * stride[1]; /* stockham.py:457 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset        = offset + index_along_d * stride[d]; /* stockham.py:463 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset     = offset + batch * stride[dim]; /* stockham.py:467 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf, offset + tid1 * stride[1] + (tid0 + 0) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 32) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 64) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1] = load_cb(
            buf, offset + tid1 * stride[1] + (tid0 + 96) * stride0, load_cb_data, nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 0) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 32) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 64) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1] = load_cb(
                buf, offset + tid1 * stride[1] + (tid0 + 96) * stride0, load_cb_data, nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    ip_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 0) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 32) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 64) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf,
                 offset + tid1 * stride[1] + (tid0 + 96) * stride0,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 0) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 32) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 64) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf,
                     offset + tid1 * stride[1] + (tid0 + 96) * stride0,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void ip_inverse_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ bufre,
    real_type_t<scalar_type>* __restrict__ bufim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset           = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0  = (sb == SB_UNIT) ? (1) : (stride[0]);
    auto         load_cb  = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset      = tile_index * 16 * stride[1]; /* stockham.py:457 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset        = offset + index_along_d * stride[d]; /* stockham.py:463 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset     = offset + batch * stride[dim]; /* stockham.py:467 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0],
               bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0],
                   bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    ip_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            bufre[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 0) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 32) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 64) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            bufre[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            bufim[offset + tid1 * stride[1] + (tid0 + 96) * stride0]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
/* stockham.py:765 */
template <typename scalar_type,
          StrideBin sb,
          bool      apply_large_twiddle,
          size_t    large_twiddle_base = 8>
__device__ void op_inverse_length128_SBCC_device(scalar_type* __restrict__ lds,
                                                 const scalar_type* __restrict__ twiddles,
                                                 size_t             stride_lds,
                                                 unsigned int       offset_lds,
                                                 bool               write,
                                                 const scalar_type* large_twiddles,
                                                 size_t             trans_local)
{
    size_t       thread;
    scalar_type  R[8];
    scalar_type  W;
    scalar_type  t;
    const size_t lstride = (sb == SB_UNIT) ? (1) : (stride_lds);
    thread               = threadIdx.x % 32; /* stockham.py:731 */

    // pass 0
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 16) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 48) * lstride]; /* stockham.py:542 */
    R[4] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[5] = lds[offset_lds + (thread + 80) * lstride]; /* stockham.py:542 */
    R[6] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */
    R[7] = lds[offset_lds + (thread + 112) * lstride]; /* stockham.py:542 */

    InvRad8B1(&R[0], &R[1], &R[2], &R[3], &R[4], &R[5], &R[6], &R[7]); /* stockham.py:566 */

    __syncthreads();
    if(write && thread < 16)
    {
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 1) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 2) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 3) * lstride]
            = R[3]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 4) * lstride]
            = R[4]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 5) * lstride]
            = R[5]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 6) * lstride]
            = R[6]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 1) * 8 + thread % 1 + 7) * lstride]
            = R[7]; /* stockham.py:577 */
    }

    // pass 1
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = {twiddles[7 + 3 * (thread % 8)].x,
         -twiddles[7 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = {twiddles[8 + 3 * (thread % 8)].x,
         -twiddles[8 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = {twiddles[9 + 3 * (thread % 8)].x,
         -twiddles[9 + 3 * (thread % 8)].y}; /* generator.py:1065 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    InvRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 8) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 16) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 8) * 32 + thread % 8 + 24) * lstride]
            = R[3]; /* stockham.py:577 */
    }

    // pass 2
    __syncthreads();
    R[0] = lds[offset_lds + (thread + 0) * lstride]; /* stockham.py:542 */
    R[1] = lds[offset_lds + (thread + 32) * lstride]; /* stockham.py:542 */
    R[2] = lds[offset_lds + (thread + 64) * lstride]; /* stockham.py:542 */
    R[3] = lds[offset_lds + (thread + 96) * lstride]; /* stockham.py:542 */

    W    = {twiddles[31 + 3 * (thread % 32)].x,
         -twiddles[31 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:555 */
    t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:556 */
    R[1] = t; /* stockham.py:557 */
    W    = {twiddles[32 + 3 * (thread % 32)].x,
         -twiddles[32 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:555 */
    t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:556 */
    R[2] = t; /* stockham.py:557 */
    W    = {twiddles[33 + 3 * (thread % 32)].x,
         -twiddles[33 + 3 * (thread % 32)].y}; /* generator.py:1065 */
    t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:555 */
    t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:556 */
    R[3] = t; /* stockham.py:557 */

    InvRad4B1(&R[0], &R[1], &R[2], &R[3]); /* stockham.py:566 */

    if(apply_large_twiddle)
    {
        // large twiddle multiplication
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 0) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 0) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[0].x - W.y * R[0].y; /* stockham.py:283 */
        t.y  = W.y * R[0].x + W.x * R[0].y; /* stockham.py:284 */
        R[0] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 32) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 32) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[1].x - W.y * R[1].y; /* stockham.py:283 */
        t.y  = W.y * R[1].x + W.x * R[1].y; /* stockham.py:284 */
        R[1] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 64) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 64) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[2].x - W.y * R[2].y; /* stockham.py:283 */
        t.y  = W.y * R[2].x + W.x * R[2].y; /* stockham.py:284 */
        R[2] = t; /* stockham.py:285 */
        W    = {TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                      ((thread % 32) + 96) * trans_local)
                 .x,
             -TW2step<scalar_type, large_twiddle_base>(large_twiddles,
                                                       ((thread % 32) + 96) * trans_local)
                  .y}; /* generator.py:1065 */
        t.x  = W.x * R[3].x - W.y * R[3].y; /* stockham.py:283 */
        t.y  = W.y * R[3].x + W.x * R[3].y; /* stockham.py:284 */
        R[3] = t; /* stockham.py:285 */
    }
    __syncthreads();
    if(write)
    {
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 0) * lstride]
            = R[0]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 32) * lstride]
            = R[1]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 64) * lstride]
            = R[2]; /* stockham.py:577 */
        lds[offset_lds + ((thread / 32) * 128 + thread % 32 + 96) * lstride]
            = R[3]; /* stockham.py:577 */
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__
    __launch_bounds__(512) void op_inverse_length128_SBCC(const scalar_type* __restrict__ twiddles,
                                                          const scalar_type* large_twiddles,
                                                          const size_t       dim,
                                                          const size_t* __restrict__ lengths,
                                                          const size_t* __restrict__ stride_in,
                                                          const size_t* __restrict__ stride_out,
                                                          const size_t       nbatch,
                                                          const unsigned int lds_padding,
                                                          void* __restrict__ load_cb_fn,
                                                          void* __restrict__ load_cb_data,
                                                          uint32_t load_cb_lds_bytes,
                                                          void* __restrict__ store_cb_fn,
                                                          void* __restrict__ store_cb_data,
                                                          scalar_type* __restrict__ buf_in,
                                                          scalar_type* __restrict__ buf_out)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_inverse_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    scalar_type* __restrict__ buf_in,
    real_type_t<scalar_type>* __restrict__ buf_outre,
    real_type_t<scalar_type>* __restrict__ buf_outim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = load_cb(buf_in,
                      offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                      load_cb_data,
                      nullptr);
        ; /* stockham.py:493 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = load_cb(buf_in,
                          offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in,
                          load_cb_data,
                          nullptr);
            ; /* stockham.py:493 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_inverse_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ buf_inre,
    real_type_t<scalar_type>* __restrict__ buf_inim,
    scalar_type* __restrict__ buf_out)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                 store_cb_data,
                 nullptr);
        store_cb(buf_out,
                 offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                 lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                 store_cb_data,
                 nullptr);
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1],
                     store_cb_data,
                     nullptr);
            store_cb(buf_out,
                     offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out,
                     lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1],
                     store_cb_data,
                     nullptr);
        }
    }
}
/* stockham.py:709 */
template <typename scalar_type,
          StrideBin    sb,
          EmbeddedType ebtype,
          CallbackType cbtype,
          bool         apply_large_twiddle,
          size_t       large_twiddle_base = 8>
__global__ __launch_bounds__(512) void op_inverse_length128_SBCC(
    const scalar_type* __restrict__ twiddles,
    const scalar_type* large_twiddles,
    const size_t       dim,
    const size_t* __restrict__ lengths,
    const size_t* __restrict__ stride_in,
    const size_t* __restrict__ stride_out,
    const size_t       nbatch,
    const unsigned int lds_padding,
    void* __restrict__ load_cb_fn,
    void* __restrict__ load_cb_data,
    uint32_t load_cb_lds_bytes,
    void* __restrict__ store_cb_fn,
    void* __restrict__ store_cb_data,
    real_type_t<scalar_type>* __restrict__ buf_inre,
    real_type_t<scalar_type>* __restrict__ buf_inim,
    real_type_t<scalar_type>* __restrict__ buf_outre,
    real_type_t<scalar_type>* __restrict__ buf_outim)
{
    // this kernel:
    //   uses 32 threads per transform
    //   does 16 transforms per thread block
    // therefore it should be called with 512 threads per thread block
    extern __shared__ unsigned char __align__(sizeof(scalar_type)) lds_uchar[];
    scalar_type* __restrict__ lds = reinterpret_cast<scalar_type*>(lds_uchar);
    size_t       offset_in        = 0;
    size_t       offset_out       = 0;
    unsigned int offset_lds;
    size_t       stride_lds;
    size_t       batch;
    size_t       transform;
    size_t       thread;
    bool         write;
    const size_t stride0_in  = (sb == SB_UNIT) ? (1) : (stride_in[0]);
    const size_t stride0_out = (sb == SB_UNIT) ? (1) : (stride_out[0]);
    auto         load_cb     = get_load_cb<scalar_type, cbtype>(load_cb_fn);
    auto         store_cb    = get_store_cb<scalar_type, cbtype>(store_cb_fn);

    // large twiddles
    __shared__ scalar_type large_twd_lds[(apply_large_twiddle && large_twiddle_base < 8)
                                             ? ((1 << large_twiddle_base) * 3)
                                             : (0)];
    if(apply_large_twiddle && large_twiddle_base < 8)
    {
        size_t ltwd_id = threadIdx.x;
        while(ltwd_id < (1 << large_twiddle_base) * 3)
        {
            large_twd_lds[ltwd_id] = large_twiddles[ltwd_id]; /* stockham.py:268 */
            ltwd_id += 512; /* stockham.py:269 */
        }
    }

    // offsets
    size_t tile_index;
    size_t tile_length;

    // calculate offset for each tile:
    //   tile_index  now means index of the tile along dim1
    //   tile_length now means number of tiles along dim1
    size_t plength = 1;
    size_t remaining;
    size_t index_along_d;
    tile_length = (lengths[1] - 1) / 16 + 1; /* stockham.py:453 */
    plength     = tile_length; /* stockham.py:454 */
    tile_index  = blockIdx.x % tile_length; /* stockham.py:455 */
    remaining   = blockIdx.x / tile_length; /* stockham.py:456 */
    offset_in   = tile_index * 16 * stride_in[1]; /* generator.py:992 */
    offset_out  = tile_index * 16 * stride_out[1]; /* generator.py:993 */
    for(int d = 2; d < dim; ++d)
    {
        plength       = plength * lengths[d]; /* stockham.py:460 */
        index_along_d = remaining % lengths[d]; /* stockham.py:461 */
        remaining     = remaining / lengths[d]; /* stockham.py:462 */
        offset_in     = offset_in + index_along_d * stride_in[d]; /* generator.py:992 */
        offset_out    = offset_out + index_along_d * stride_out[d]; /* generator.py:993 */
    }

    transform  = tile_index * 16 + threadIdx.x / 32; /* stockham.py:465 */
    batch      = blockIdx.x / plength; /* stockham.py:466 */
    offset_in  = offset_in + batch * stride_in[dim]; /* generator.py:992 */
    offset_out = offset_out + batch * stride_out[dim]; /* generator.py:993 */
    offset_lds = 128 * (transform % 16); /* stockham.py:468 */

    if(batch >= nbatch)
    {
        return;
    }

    // load global
    bool   edge;
    size_t tid0;
    size_t tid1;
    edge = ((tile_index + 1) * 16 > lengths[1]) ? true : false; /* stockham.py:485 */
    tid1 = threadIdx.x % 16; /* stockham.py:486 */
    tid0 = threadIdx.x / 16; /* stockham.py:487 */
    if(!edge)
    {
        lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
        lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
            = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
               buf_inim[offset_in + tid1 * stride_in[1]
                        + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 0) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 0) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 32) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 32) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 64) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 64) * stride0_in]}; /* generator.py:872 */
            lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1]
                = {buf_inre[offset_in + tid1 * stride_in[1] + (tid0 + 96) * stride0_in],
                   buf_inim[offset_in + tid1 * stride_in[1]
                            + (tid0 + 96) * stride0_in]}; /* generator.py:872 */
        }
    }

    // handle even-length real to complex pre-process in lds before transform
    if(ebtype == EmbeddedType::C2Real_PRE)
    {
        __syncthreads();

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                           128 - thread % 64 - 0,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        real_pre_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                           128 - thread % 64 - 32,
                                                           64,
                                                           &lds[offset_lds],
                                                           0,
                                                           &twiddles[128]); /* stockham.py:338 */

        __syncthreads();
    }

    // transform
    write = true; /* stockham.py:681 */
    op_inverse_length128_SBCC_device<scalar_type, SB_UNIT, apply_large_twiddle, large_twiddle_base>(
        lds,
        twiddles,
        stride_lds,
        offset_lds,
        write,
        (apply_large_twiddle && large_twiddle_base < 8) ? (large_twd_lds) : (large_twiddles),
        transform); /* stockham.py:686 */

    // handle even-length complex to real post-process in lds after transform
    if(ebtype == EmbeddedType::Real2C_POST)
    {
        __syncthreads();

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 0,
                                                            128 - thread % 64 - 0,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */

        real_post_process_kernel_inplace<scalar_type, true>(thread % 64 + 32,
                                                            128 - thread % 64 - 32,
                                                            64,
                                                            &lds[offset_lds],
                                                            0,
                                                            &twiddles[128]); /* stockham.py:338 */
    }

    // store global
    __syncthreads();
    if(!edge)
    {
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
        buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
        buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
            = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
    }
    if(edge)
    {
        if(tile_index * 16 + tid1 < lengths[1])
        {
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 0) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 0) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 32) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 32) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 64) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 64) * 1].y; /* generator.py:908 */
            buf_outre[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].x; /* generator.py:906 */
            buf_outim[offset_out + tid1 * stride_out[1] + (tid0 + 96) * stride0_out]
                = lds[tid1 * 128 + lds_padding + (tid0 + 96) * 1].y; /* generator.py:908 */
        }
    }
}
POWX_LARGE_SBCC_GENERATOR(rocfft_internal_dfn_dp_ci_ci_sbcc_128,
                          ip_forward_length128_SBCC,
                          ip_inverse_length128_SBCC,
                          op_forward_length128_SBCC,
                          op_inverse_length128_SBCC,
                          double2);
POWX_LARGE_SBCC_GENERATOR(rocfft_internal_dfn_sp_ci_ci_sbcc_128,
                          ip_forward_length128_SBCC,
                          ip_inverse_length128_SBCC,
                          op_forward_length128_SBCC,
                          op_inverse_length128_SBCC,
                          float2);